{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Larger LSTM Network to Generate Text for Alice in Wonderland\n",
    "import numpy\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# load ascii text and covert to lowercase\n",
    "import sys\n",
    "\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import os\n",
    "import sys\n",
    "wordlists = PlaintextCorpusReader(\"Nepali_Corpus\", '.*txt')\n",
    "data = wordlists.fileids()[:50]\n",
    "text = []\n",
    "invalid = 0\n",
    "for i in data:\n",
    "    with open(os.path.join(\"Nepali_Corpus\",i),encoding='utf8') as file:\n",
    "        try:\n",
    "            text.append(file.read())\n",
    "        except UnicodeDecodeError :\n",
    "            print(i)\n",
    "            invalid+=1\n",
    "print(invalid)\n",
    "raw_text = \"\\n\".join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '(', ')', ',', '-', '.', '/', '?', 'm', '\\xa0', '¥', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'े', 'ै', 'ो', 'ौ', '्', '।', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '\\u200d', '–', '‘', '’']\n",
      "Total Characters:  70766\n",
      "Total Vocab:  85\n",
      "Total Patterns:  70746\n"
     ]
    }
   ],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 20\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)\n",
    "# reshape X to be [samples, time steps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(dataX,dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "न् । शनिबार उनले चित \n",
      "\n",
      "न् । शनिबार उनले चित् (‘र् औोर् (फि् (‘र् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि् (फि\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (''.join([int_to_char[value] for value in pattern]), \"\\n\")\n",
    "print(\"\".join([int_to_char[value] for value in pattern]),end=\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = [pattern]\n",
    "    index = clf.predict(x)[0]\n",
    "    result = int_to_char[index]\n",
    "    print(result,sep='',end='')\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
