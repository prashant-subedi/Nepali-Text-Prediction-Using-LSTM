{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  1037\n",
      "Total Vocab:  58\n"
     ]
    }
   ],
   "source": [
    "# Load Larger LSTM network and generate text\n",
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# load ascii text and covert to lowercase\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import os\n",
    "import sys\n",
    "wordlists = PlaintextCorpusReader(\"Nepali_Corpus\", '.*txt')\n",
    "data = wordlists.fileids()[:1]\n",
    "text = []\n",
    "for i in data:\n",
    "    with open(os.path.join(\"Nepali_Corpus\",i)) as file:\n",
    "        text.append(file.read())\n",
    "text = \"\\n\".join(text)\n",
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = text[i:i + seq_length]\n",
    "    seq_out = text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  937\n"
     ]
    }
   ],
   "source": [
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56896552],\n",
       "       [0.20689655],\n",
       "       [0.63793103],\n",
       "       [0.70689655],\n",
       "       [0.48275862],\n",
       "       [0.5       ],\n",
       "       [0.75862069],\n",
       "       [0.60344828],\n",
       "       [0.01724138],\n",
       "       [0.94827586],\n",
       "       [0.01724138],\n",
       "       [0.51724138],\n",
       "       [0.72413793],\n",
       "       [0.62068966],\n",
       "       [0.87931034],\n",
       "       [0.56896552],\n",
       "       [0.01724138],\n",
       "       [0.96551724],\n",
       "       [0.68965517],\n",
       "       [0.75862069],\n",
       "       [0.60344828],\n",
       "       [0.87931034],\n",
       "       [0.60344828],\n",
       "       [0.81034483],\n",
       "       [0.98275862],\n",
       "       [0.62068966],\n",
       "       [0.81034483],\n",
       "       [0.01724138],\n",
       "       [0.60344828],\n",
       "       [0.72413793],\n",
       "       [0.62068966],\n",
       "       [0.72413793],\n",
       "       [0.32758621],\n",
       "       [0.01724138],\n",
       "       [0.56896552],\n",
       "       [0.72413793],\n",
       "       [0.4137931 ],\n",
       "       [0.72413793],\n",
       "       [0.01724138],\n",
       "       [0.48275862],\n",
       "       [0.32758621],\n",
       "       [0.72413793],\n",
       "       [0.20689655],\n",
       "       [0.72413793],\n",
       "       [0.18965517],\n",
       "       [0.67241379],\n",
       "       [0.06896552],\n",
       "       [0.24137931],\n",
       "       [0.82758621],\n",
       "       [0.01724138],\n",
       "       [0.5       ],\n",
       "       [0.87931034],\n",
       "       [0.60344828],\n",
       "       [0.29310345],\n",
       "       [0.70689655],\n",
       "       [0.60344828],\n",
       "       [0.5       ],\n",
       "       [0.87931034],\n",
       "       [0.60344828],\n",
       "       [0.67241379],\n",
       "       [0.70689655],\n",
       "       [0.60344828],\n",
       "       [0.56896552],\n",
       "       [0.70689655],\n",
       "       [0.01724138],\n",
       "       [0.4137931 ],\n",
       "       [0.74137931],\n",
       "       [0.63793103],\n",
       "       [0.87931034],\n",
       "       [0.60344828],\n",
       "       [0.4137931 ],\n",
       "       [0.70689655],\n",
       "       [0.01724138],\n",
       "       [0.44827586],\n",
       "       [0.72413793],\n",
       "       [0.18965517],\n",
       "       [0.20689655],\n",
       "       [0.84482759],\n",
       "       [0.01724138],\n",
       "       [0.31034483],\n",
       "       [0.01724138],\n",
       "       [0.89655172],\n",
       "       [0.01724138],\n",
       "       [0.65517241],\n",
       "       [0.48275862],\n",
       "       [0.72413793],\n",
       "       [0.53448276],\n",
       "       [0.70689655],\n",
       "       [0.60344828],\n",
       "       [0.01724138],\n",
       "       [0.68965517],\n",
       "       [0.81034483],\n",
       "       [0.36206897],\n",
       "       [0.86206897],\n",
       "       [0.0862069 ],\n",
       "       [0.37931034],\n",
       "       [0.70689655],\n",
       "       [0.01724138],\n",
       "       [0.12068966],\n",
       "       [0.13793103]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]/n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / float(n_vocab)\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 100, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "937/937 [==============================] - 14s 15ms/step - loss: 3.8141\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.81406, saving model to weights-improvement-01-3.8141.hdf5\n",
      "Epoch 2/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.4859\n",
      "\n",
      "Epoch 00002: loss improved from 3.81406 to 3.48589, saving model to weights-improvement-02-3.4859.hdf5\n",
      "Epoch 3/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.4371\n",
      "\n",
      "Epoch 00003: loss improved from 3.48589 to 3.43709, saving model to weights-improvement-03-3.4371.hdf5\n",
      "Epoch 4/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.4314\n",
      "\n",
      "Epoch 00004: loss improved from 3.43709 to 3.43137, saving model to weights-improvement-04-3.4314.hdf5\n",
      "Epoch 5/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.4193\n",
      "\n",
      "Epoch 00005: loss improved from 3.43137 to 3.41929, saving model to weights-improvement-05-3.4193.hdf5\n",
      "Epoch 6/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.4168\n",
      "\n",
      "Epoch 00006: loss improved from 3.41929 to 3.41678, saving model to weights-improvement-06-3.4168.hdf5\n",
      "Epoch 7/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.4111\n",
      "\n",
      "Epoch 00007: loss improved from 3.41678 to 3.41106, saving model to weights-improvement-07-3.4111.hdf5\n",
      "Epoch 8/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.4111\n",
      "\n",
      "Epoch 00008: loss did not improve from 3.41106\n",
      "Epoch 9/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.4075\n",
      "\n",
      "Epoch 00009: loss improved from 3.41106 to 3.40750, saving model to weights-improvement-09-3.4075.hdf5\n",
      "Epoch 10/20\n",
      "937/937 [==============================] - 12s 12ms/step - loss: 3.4123\n",
      "\n",
      "Epoch 00010: loss did not improve from 3.40750\n",
      "Epoch 11/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.4000\n",
      "\n",
      "Epoch 00011: loss improved from 3.40750 to 3.39996, saving model to weights-improvement-11-3.4000.hdf5\n",
      "Epoch 12/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.4019\n",
      "\n",
      "Epoch 00012: loss did not improve from 3.39996\n",
      "Epoch 13/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.4050\n",
      "\n",
      "Epoch 00013: loss did not improve from 3.39996\n",
      "Epoch 14/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.3867\n",
      "\n",
      "Epoch 00014: loss improved from 3.39996 to 3.38668, saving model to weights-improvement-14-3.3867.hdf5\n",
      "Epoch 15/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.4040\n",
      "\n",
      "Epoch 00015: loss did not improve from 3.38668\n",
      "Epoch 16/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.3889\n",
      "\n",
      "Epoch 00016: loss did not improve from 3.38668\n",
      "Epoch 17/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.3944\n",
      "\n",
      "Epoch 00017: loss did not improve from 3.38668\n",
      "Epoch 18/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.3919\n",
      "\n",
      "Epoch 00018: loss did not improve from 3.38668\n",
      "Epoch 19/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.3986\n",
      "\n",
      "Epoch 00019: loss did not improve from 3.38668\n",
      "Epoch 20/20\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 3.3935\n",
      "\n",
      "Epoch 00020: loss did not improve from 3.38668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6f642cd978>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# load the network weights\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 47, 12, 49, 1, 30, 42, 36, 51, 33, 33, 41, 1, 6, 28, 44, 29, 37, 42, 12, 51, 35, 33, 1, 38, 41, 40, 43, 2, 1, 12, 47, 12, 43, 1, 6, 27, 42, 12, 41, 35, 43, 2, 1, 31, 42, 19, 34, 1, 31, 35, 41, 36, 2, 1, 6, 5, 12, 42, 24, 1, 13, 22, 51, 12, 41, 2, 1, 39, 5, 14, 43, 24, 41, 1, 28, 41, 29, 42, 24, 1, 36, 14, 41, 34, 24, 12, 49, 1, 6, 32, 42, 28, 34, 1, 18, 1, 52, 1, 30]\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(pattern)\n",
    "gen_data = [int_to_char[value] for value in pattern]\n",
    "gen_data.append(\"***\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    print(index)\n",
    "    result = int_to_char[index]\n",
    "    try:\n",
    "        gen_data.append(int_to_char[result])\n",
    "    except:\n",
    "        gen_data.append(\" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'हेको फिल्ममा अनुपविक्रम शाही, केकी अधिकारी, बिजय बराल, अंकित खड्का, संगीता नापित लगायतको अभिनय छ । फ***                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
